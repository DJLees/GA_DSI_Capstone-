{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 different models on NEM data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading compotents that are useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kB3O21hLrIsq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,TimeDistributed,Flatten,Dropout,Conv1D,MaxPooling1D\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "#FB Prophet has altered the register in Matplotlib and a solution has not been found. This work around however works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data. This is a csv produced by the downloading notebook. It has been split off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMwBiMKLrIsv"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./HalfHourly_Data.csv', index_col=0)\n",
    "\n",
    "data.index = pd.to_datetime(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a daily mean dataframe\n",
    "\n",
    "The downloaded data is half hourly. This is simply too much data to proceed with at the moment. So instead a daily figure table is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "XhHEPEizrIsy",
    "outputId": "f59ddb8a-7a0c-4ae1-eea8-b3b239de1b87",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "daily_mean = pd.DataFrame()\n",
    "\n",
    "daily_mean[\"VIC_PRICE\"] = data[\"VIC_PRICE\"].resample('D').mean()\n",
    "daily_mean[\"VIC_PRICE_median\"] = data[\"VIC_PRICE\"].resample('D').median()\n",
    "daily_mean['VIC_PRICE_wt_mean'] = (data['VIC_PRICE']*data['VIC_DEMAND']).resample('D').sum()/data['VIC_DEMAND'].resample('D').sum()\n",
    "daily_mean[\"VIC_PRICE_std\"] = data[\"VIC_PRICE\"].resample('D').std().interpolate(method='polynomial', order=1)\n",
    "daily_mean[\"VIC_PRICE_diff\"] = daily_mean[\"VIC_PRICE\"].diff()\n",
    "\n",
    "\n",
    "daily_mean.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler choosing\n",
    "\n",
    "Due to a few large spikes, scaling really helps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QlEFmuRFuEf"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,RobustScaler,QuantileTransformer,StandardScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "minmaxscale = MinMaxScaler()\n",
    "\n",
    "robustscale = RobustScaler()\n",
    "\n",
    "qt = QuantileTransformer(n_quantiles=200)\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper,gen_features\n",
    "\n",
    "features=[]\n",
    "transformers = [StandardScaler,MinMaxScaler,QuantileTransformer,RobustScaler]\n",
    "#transformers = [QuantileTransformer]\n",
    "\n",
    "\n",
    "for transformer in transformers:\n",
    "#     feature = gen_features([['VIC_PRICE']],classes=[{'class':QuantileTransformer,'n_quantiles':200}])\n",
    "    feature = gen_features([['VIC_PRICE']],classes=[transformer])\n",
    "    features.append((feature[0][0],feature[0][1],{'alias':transformer.__name__}))\n",
    "\n",
    "mapper = DataFrameMapper(features,df_out=True,input_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter the Lag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = input(\"What lag should be used?\")\n",
    "\n",
    "lag = int(lag)\n",
    "\n",
    "print(\"\")\n",
    "print(\"The lag is set at\", lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z7A6bItDMEdS"
   },
   "source": [
    "<a id=\"reshape-the-data-to-work-with-the-lstm\"></a>\n",
    "## Long short-term memory (LSTM) - Recurrent Neural Network (RNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxkKcMHJvWn5"
   },
   "outputs": [],
   "source": [
    "def create_data(timeseries, lag=1, as_array=True):\n",
    "    # print(timeseries)\n",
    "    if not isinstance(timeseries, pd.Series):\n",
    "        timeseries = pd.Series(timeseries.ravel())\n",
    "    y = timeseries[lag:]\n",
    "    # print(y.shape)\n",
    "    X = pd.DataFrame({'lag'+str(lag-i):timeseries.shift(-i) for i in range(0, lag)}).dropna().iloc[:-1, :]\n",
    "#     X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "    X =X.values.reshape(X.shape[0], 1, X.shape[1])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GqPXzA2EZ23Y",
    "outputId": "30642aaf-cf45-4370-c6ca-b4c3f13a4aea",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(2, input_shape=(None, lag)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "lstm_results = pd.DataFrame()\n",
    "scaler = 'RobustScaler'\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "print(tscv)  \n",
    "X=daily_mean\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "  \n",
    "    train_transform = mapper.fit_transform(X_train)\n",
    "    test_transform = mapper.fit_transform(X_test)\n",
    "\n",
    "    trainX, trainY = create_data(train_transform[scaler], lag)\n",
    "    testX, testY = create_data(test_transform[scaler], lag)\n",
    "  # print(trainX.shape)\n",
    "    model.fit(trainX, trainY, epochs=20, batch_size=1, verbose=1)\n",
    "\n",
    "    #trainPredict = pd.Series(model.predict(trainX).squeeze(),index=trainY.index)\n",
    "    testPredict = pd.Series(model.predict(testX).squeeze(),index=testY.index)\n",
    "    lstm_results['testPredict_'+str(i)] = pd.Series(model.predict(testX).squeeze(),index=testY.index)\n",
    "    lstm_results['trainPredict_'+str(i)] = pd.Series(model.predict(trainX).squeeze(),index=trainY.index)\n",
    "    lstm_results['trainY_'+str(i)] = trainY\n",
    "    lstm_results['testY_'+str(i)] = testY\n",
    "    \n",
    "#     pd.Series(model.predict(trainX).squeeze(),index=trainX.index)\n",
    "    \n",
    "    #trainY.plot(figsize=(14,7))\n",
    "    testY.plot(figsize=(14,7))\n",
    "\n",
    "    #trainPredict.plot(figsize=(14,7))\n",
    "    testPredict.plot(figsize=(14,7))\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets add multiple Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4fgcfFaw2S8"
   },
   "outputs": [],
   "source": [
    "def create_multi_data(timeseries, nfeatures, target = 'VIC_PRICE',lag=1):\n",
    "    # print(timeseries)\n",
    "    # if not isinstance(timeseries, pd.Series):\n",
    "        # timeseries = pd.Series(timeseries.ravel())\n",
    "#     minmax = MinMaxScaler()\n",
    "#     X_train = minmax.fit_transform(X_train)\n",
    "#     X_test = minmax.transform(X_test)\n",
    "    feature = gen_features([[col] for col in timeseries.columns],classes=[{'class':QuantileTransformer,'n_quantiles':100,'output_distribution':'normal'}])\n",
    "#     features.append((feature[0][0],feature[0][1],{'alias':transformer.__name__}))\n",
    "\n",
    "    mapper = DataFrameMapper(feature,df_out=True,input_df=True)\n",
    "    timeseries = mapper.fit_transform(timeseries)\n",
    "    y = timeseries[target][lag:]\n",
    "    # print(y.shape)\n",
    "    \n",
    "    Xs=[]\n",
    "    for col in timeseries.columns[0:nfeatures]:\n",
    "    \n",
    "        Xs.append(pd.DataFrame({'lag'+str(lag-i):timeseries[col].shift(-i) for i in range(0, lag)}).dropna().iloc[:-1, :])\n",
    "\n",
    "    X = pd.concat(Xs,axis=1)\n",
    "    # X = pd.DataFrame({'lag'+str(lag-i):timeseries.shift(-i) for i in range(0, lag)}).dropna().iloc[:-1, :]\n",
    "    X = np.reshape(X.values, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeatures = 3\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Dense(200))\n",
    "# \n",
    "# model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50,input_shape=(None, lag*nfeatures)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import robust_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "earlystop=EarlyStopping(monitor='loss', min_delta=0.1, patience=10, verbose=1, mode='auto', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cd8CwOhDxTuF",
    "outputId": "db32184f-7371-4f9f-f293-57745038dcc0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "nfeatures = 5\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "print(tscv)  \n",
    "# X=daily_mean.rolling(3).mean().dropna()\n",
    "X=daily_mean.dropna()\n",
    "xCol= daily_mean.columns\n",
    "for train_index, test_index in tscv.split(X):\n",
    "  #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "  \n",
    "\n",
    "    trainX, trainY = create_multi_data(X_train,nfeatures, lag=lag)\n",
    "    testX, testY = create_multi_data(X_test, nfeatures,lag=lag)\n",
    "\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10,input_shape=(None, lag*nfeatures)))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "    model.fit(trainX, trainY, epochs=80, batch_size=64, verbose=1, callbacks=[reduce_lr,earlystop])\n",
    "    \n",
    "    trainPredict =  pd.DataFrame(model.predict(trainX),index=trainY.index)\n",
    "    testPredict = pd.DataFrame(model.predict(testX),index=testY.index)\n",
    "     \n",
    "    #trainY.plot(figsize=(14,7))\n",
    "    #testY.plot(figsize=(14,7))\n",
    "  \n",
    "\n",
    "  # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iPKXfhy_xtiZ",
    "outputId": "a4dfcb63-c5df-4259-fb00-df9d758df348"
   },
   "outputs": [],
   "source": [
    "# plt.plot()\n",
    "# plt.plot(trainY.ravel(), label=\"Test\")\n",
    "# plt.plot(model.predict(trainX), label=\"Train\")\n",
    "trainPredict.plot(ylim = (-2,2))\n",
    "trainY.plot(ylim = (-2,2))\n",
    "\n",
    "testPredict.plot(ylim = (-2,2))\n",
    "testY.plot(ylim = (-2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.index[0]-X_train.index[1]\n",
    "dt = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zoQUR0kvxj2f",
    "outputId": "d5372607-6ea6-4e60-eac0-cc0e4b36597e"
   },
   "outputs": [],
   "source": [
    "NFFT = 1024*2*2  # the length of the windowing segments\n",
    "Fs = (1.0 / dt)  # the sampling frequency\n",
    "\n",
    "Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zoQUR0kvxj2f",
    "outputId": "d5372607-6ea6-4e60-eac0-cc0e4b36597e"
   },
   "outputs": [],
   "source": [
    "_,_=plt.psd(X_train['VIC_PRICE'].dropna().values, NFFT=NFFT, Fs=Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zoQUR0kvxj2f",
    "outputId": "d5372607-6ea6-4e60-eac0-cc0e4b36597e"
   },
   "outputs": [],
   "source": [
    "plt.specgram(X_train['VIC_PRICE'].dropna().values, NFFT=NFFT, Fs=1 ,noverlap=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['VIC_PRICE'].dropna().values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(daily_mean[[\"VIC_PRICE\"]],daily_mean[[\"VIC_PRICE_diff\"]], test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gbr.fit(Xtrain.values.reshape(-1,1),ytrain)\n",
    "\n",
    "yPredict_train = gbr.predict(Xtrain.values.reshape(-1,1))\n",
    "yPredict_test = gbr.predict(Xtest.values.reshape(-1,1))\n",
    "\n",
    "# pd.plotting.register_matplotlib_converters()\n",
    "ytrain.loc[:,'yPredictTrain'] = pd.DataFrame(yPredict_train,index=ytrain.index)\n",
    "ytest.loc[:,'yPredictTest'] = pd.DataFrame(yPredict_test,index=ytest.index)\n",
    "\n",
    "# ytrain.plot()\n",
    "# yPredict.shape,ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boostdata = daily_mean[[\"VIC_PRICE\",\"VIC_PRICE_diff\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingRegressor(min_samples_split=5,min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(warm_start=False)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for train_index, test_index in tscv.split(boostdata):\n",
    "  #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "  \n",
    "    xtrain, xtest = boostdata[[\"VIC_PRICE\"]].iloc[train_index], boostdata[[\"VIC_PRICE\"]].iloc[test_index]\n",
    "    ytrain, ytest = boostdata[[\"VIC_PRICE_diff\"]].iloc[train_index], boostdata[[\"VIC_PRICE_diff\"]].iloc[test_index]\n",
    "\n",
    "#     print(xtrain,xtest,ytrain,ytest)\n",
    "#     break\n",
    "    gbr.fit(xtrain,ytrain.values.ravel())\n",
    "\n",
    "    yPredict_train = gbr.predict(xtrain.values)\n",
    "    yPredict_test = gbr.predict(xtest.values)\n",
    "\n",
    "    # pd.plotting.register_matplotlib_converters()\n",
    "    ytrain.loc[:,'yPredictTrain'] = pd.DataFrame(yPredict_train,index=ytrain.index)\n",
    "    ytest.loc[:,'yPredictTest'] = pd.DataFrame(yPredict_test,index=ytest.index)\n",
    "    ytrain.plot()\n",
    "    ytest.plot()\n",
    "\n",
    "    # ytrain.plot()\n",
    "    # yPredict.shape,ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yPredict.reset_index().sort_values('index').set_index('index').plot()\n",
    "ytrain.plot()\n",
    "# .plot('VIC_PRICE_diff')\n",
    "ytest.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain.reset_index(drop=True).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Prophet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "import math\n",
    "m = Prophet()\n",
    "\n",
    "FBdata  = pd.DataFrame()\n",
    "\n",
    "FBdata['y'] = (data[\"VIC_PRICE\"].resample('D').mean()) \n",
    "\n",
    "FBdata['ds'] = FBdata.index\n",
    "FBdata = FBdata[['ds','y']]\n",
    "#df = FBdata[:258]\n",
    "#test = FBdata[258:]\n",
    "\n",
    "m.fit(FBdata)\n",
    "\n",
    "future = m.make_future_dataframe(periods=50)\n",
    "forecast = m.predict(future)\n",
    "\n",
    "fig1 = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to try on the Half-hourly data.  \n",
    "m = Prophet()\n",
    "\n",
    "FBdata  = pd.DataFrame()\n",
    "pd.set_option('use_inf_as_na', True)\n",
    "FBdata['y'] = np.log(data[\"VIC_PRICE\"]) \n",
    "FBdata['ds'] = FBdata.index\n",
    "\n",
    "m.fit(FBdata)\n",
    "\n",
    "future = m.make_future_dataframe(periods=50)\n",
    "forecast = m.predict(future)\n",
    "\n",
    "fig1 = m.plot(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM on NEM data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
